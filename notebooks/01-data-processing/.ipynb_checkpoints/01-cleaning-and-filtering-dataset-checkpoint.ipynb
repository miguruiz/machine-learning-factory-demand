{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTERING THE DATASET:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along this script we will get from an initial list of products provided by our client, to a final list (as per the names and ids present within the real data), which will be used to filter our initial data in order to get a smaller, more manageable file.\n",
    "\n",
    "This process will be divided in two main steps:\n",
    "\n",
    "- Check the names in our list with the descriptions present in our data, analyze them and select a final list\n",
    "\n",
    "- Use this list to filter our data and store the resulting information in a more small and convenient file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATING THE LIST OF PRODUCTS FOR THE ANALYSIS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After rearranging the data in a more convenient manner and doing some introductory analysis of the data, we now want to get down to work with our data.\n",
    "\n",
    "A list has been given to us of the 10 products that our clients found as more relevant to their business.\n",
    "\n",
    "What we want now is to check whether the names on the list correspond to certain uniques ids, or, as seen in the previous scripts, some conflict of unicity will arise between the id of our products and their descriptions.\n",
    "\n",
    "So, we are going to check our dataframe and select from it the ids and descriptions of our products that match the indications given in our clients list. With the lists (in reality, two dictionaries) of the ids and descriptions that match every product given to us, we will decide which are the more appropriate.\n",
    "\n",
    "Perhaps some guidance from our client would be needed at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Importing packages:\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import math\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the search path of the file, the name and the separator:\n",
    "\n",
    "file_path = \"../../data/01_raw/\"\n",
    "file_name = 'b2-transactions_sample.csv' #\"b2-transactions.csv\" \n",
    "exit_path = \"../../data/02_intermediate/\"\n",
    "\n",
    "filtered_file_name=\"c1-filtered_transactions.csv\"\n",
    "\n",
    "sep=\";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the list of products provided by the client\n",
    "list_of_products=['croissant',\n",
    "                  'croissant petit',\n",
    "                  'tarta mousse 3 chocolates',\n",
    "                  'tarta de manzana 2ยบ',\n",
    "                  'palmera de chocolate'\n",
    "                  'tarta opera',\n",
    "                  'postre fresas y mascarpone',\n",
    "                  'milhojas frambuesa 2ยบ',\n",
    "                  'tortel',\n",
    "                  'baguette']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We import the dataframe:\n",
    "df=pd.read_csv(file_path+file_name, sep=sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>order_date</th>\n",
       "      <th>section</th>\n",
       "      <th>store</th>\n",
       "      <th>units_ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>446.0</td>\n",
       "      <td>POSTRE TARTALETA LIMON</td>\n",
       "      <td>10/12/2010 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>MsUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>202.0</td>\n",
       "      <td>Empanada Hojaldre y Bonito 6 rac.</td>\n",
       "      <td>25/9/2016 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>JPUP</td>\n",
       "      <td>1,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>4428.0</td>\n",
       "      <td>PRIMAVERA 2ยบ (TARTA)</td>\n",
       "      <td>11/5/2012 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>ZiUO</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8759.0</td>\n",
       "      <td>PAN DE CEREALES Y FRUTOS SECOS</td>\n",
       "      <td>13/5/2011 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>GeUP</td>\n",
       "      <td>20,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>105.0</td>\n",
       "      <td>CROISSANT CHOCOLATE</td>\n",
       "      <td>19/10/2011 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>ZiUO</td>\n",
       "      <td>0,50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id                        description          order_date  \\\n",
       "526       446.0             POSTRE TARTALETA LIMON  10/12/2010 0:00:00   \n",
       "235       202.0  Empanada Hojaldre y Bonito 6 rac.   25/9/2016 0:00:00   \n",
       "466      4428.0               PRIMAVERA 2ยบ (TARTA)   11/5/2012 0:00:00   \n",
       "16       8759.0     PAN DE CEREALES Y FRUTOS SECOS   13/5/2011 0:00:00   \n",
       "281       105.0                CROISSANT CHOCOLATE  19/10/2011 0:00:00   \n",
       "\n",
       "     section store units_ordered  \n",
       "526        0  MsUP          0,00  \n",
       "235        0  JPUP          1,00  \n",
       "466        0  ZiUO          0,00  \n",
       "16         0  GeUP         20,00  \n",
       "281        0  ZiUO          0,50  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalizing and aggregating description names\n",
    "\n",
    "Unfortunately, there is no convention for the description and one id could \n",
    "\n",
    "1. Normalize descriptions as much as possible using:\n",
    "    - Regex expressions \n",
    "    - Basic NLP for spell-checking.\n",
    "2. Create a normalization file with the following structure:\n",
    "    - Unique Product_id and normalized description\n",
    "    - Flag to indicate if the product is part of the given list, or not.  \n",
    "3. Finally review the list manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Normalizing description names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Null descriptions to 'no-description'\n",
    "df['description'].fillna('no-description', inplace = True)\n",
    "\n",
    "# Unique product descriptions\n",
    "df_descriptions_unique = pd.Series(df['description'].unique())\n",
    "\n",
    "# Most of the descriptions are in uppercase, however others are in lower:\n",
    "df['nuevo_descrip'] = df['description'].str.lower()\n",
    "\n",
    "df_descriptions_unique=df[['product_id','nuevo_descrip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace non alfanumeric with space\n",
    "df_descriptions_normalized=df_descriptions_normalized.str.replace(r'[^0-9a-zA-Zยบ()ยช:-]+', ' ') \n",
    "\n",
    "# We also notice that there are spacing issues at the begining, end of the description and between words:\n",
    "df_descriptions_normalized=df_descriptions_normalized.str.strip()\n",
    "\n",
    "# Remove multi-spacing. multi '-' and multi ':'\n",
    "df_descriptions_normalized=df_descriptions_normalized.str.replace(r' +', ' ') \n",
    "df_descriptions_normalized=df_descriptions_normalized.str.replace(r'-+', ' ') \n",
    "df_descriptions_normalized=df_descriptions_normalized.str.replace(r':+', ' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_original</th>\n",
       "      <th>desc_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GALLINA Nยบ1-50 GR</td>\n",
       "      <td>gallina nยบ1 50 gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>CARAMELOTERAPIA MENTA</td>\n",
       "      <td>carameloterapia menta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>NAPOLITANAS CREMA /PIEZA/5HORA</td>\n",
       "      <td>napolitanas crema pieza 5hora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>TABLETA 100 GR CHOCO CAFE</td>\n",
       "      <td>tableta 100 gr choco cafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>JUGO ROJO 250 ML</td>\n",
       "      <td>jugo rojo 250 ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>MOUS DE SALMON</td>\n",
       "      <td>mous de salmon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>TARTA FRESAS Y MASCARPONE</td>\n",
       "      <td>tarta fresas y mascarpone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>PATATAS FINAS HIERBAS</td>\n",
       "      <td>patatas finas hierbas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>TRUFAS HELADAS NARANJA</td>\n",
       "      <td>trufas heladas naranja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>ROSQUILLAS ALCALA YEMA</td>\n",
       "      <td>rosquillas alcala yema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      desc_original                desc_normalized\n",
       "58                GALLINA Nยบ1-50 GR              gallina nยบ1 50 gr\n",
       "281           CARAMELOTERAPIA MENTA          carameloterapia menta\n",
       "209  NAPOLITANAS CREMA /PIEZA/5HORA  napolitanas crema pieza 5hora\n",
       "266       TABLETA 100 GR CHOCO CAFE      tableta 100 gr choco cafe\n",
       "292                JUGO ROJO 250 ML               jugo rojo 250 ml\n",
       "254                  MOUS DE SALMON                 mous de salmon\n",
       "363       TARTA FRESAS Y MASCARPONE      tarta fresas y mascarpone\n",
       "449           PATATAS FINAS HIERBAS          patatas finas hierbas\n",
       "348          TRUFAS HELADAS NARANJA         trufas heladas naranja\n",
       "118          ROSQUILLAS ALCALA YEMA         rosquillas alcala yema"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict(desc_original = df_descriptions_unique, desc_normalized = df_descriptions_normalized)).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets gets get our hands dirty and apply some maths to calculate string distnace and finish cleaning all those messy product descriptions... This is what we are going to do:\n",
    "\n",
    "1. Create a dataset with pastry products by parsing the bakery catalogues, and other pastry websites. (this was done manually, by converting the pdf catalogues to txt using an external web. THe resulting file is named productos.txt)\n",
    "\n",
    "2. Following the indications from: https://medium.com/@hdezfloresmiguelangel/implementando-un-corrector-ortogr%C3%A1fico-en-python-utilizando-la-distancia-de-levenshtein-498ec0dd1105 create an spell-checker based on the products.txt dataset and the Levenshtein distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('../../data/01_additional_data/productos v3.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or known(edits3(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def edits3(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e3 for e1 in edits1(word) for e2 in edits1(e1) for e3 in edits1(e2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ceraza', 'cojan', 'corn', 'cortan', 'doran'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates(\"corazn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cortan'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"corazn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cafรฉ'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction(\"cafรฉ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic! the it seems to work. Lets now apply it to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check (line):\n",
    "    \"Given a sentence, returns spell-checks word by word\"\n",
    "    if type(line) == str and len(line) > 0:\n",
    "        new = []\n",
    "        line = line.split(\" \")\n",
    "        for word in line:\n",
    "            if type(word) == str:\n",
    "                word = correction(word)\n",
    "            new.append(word)\n",
    "        return \" \".join(new)\n",
    "            \n",
    "    else:\n",
    "        return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION! The following cell e may take a long time to process (5 hours): \n",
    "\n",
    "# spell-check word by word the dataset:\n",
    "df_descriptions_normalized = df_descriptions_normalized.apply(lambda line: spell_check(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now merge the normalized names back to the original file, and check how effective was this cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>order_date</th>\n",
       "      <th>section</th>\n",
       "      <th>store</th>\n",
       "      <th>units_ordered</th>\n",
       "      <th>desc_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>887.0</td>\n",
       "      <td>TARRINA MACEDONIA FRUTAS</td>\n",
       "      <td>4/11/2014 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>EnUP</td>\n",
       "      <td>0,00</td>\n",
       "      <td>tarrina macedonia frutas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>209.0</td>\n",
       "      <td>EMP. HOJALDRE JAMON YORK</td>\n",
       "      <td>30/6/2008 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>BmUP</td>\n",
       "      <td>0,00</td>\n",
       "      <td>el hojaldre jamon york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>720.0</td>\n",
       "      <td>ECLAIR CHOCOLATE</td>\n",
       "      <td>5/12/2013 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>RzUP</td>\n",
       "      <td>0,00</td>\n",
       "      <td>eclair chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>160.0</td>\n",
       "      <td>TORRIJAS PEQUEรAS</td>\n",
       "      <td>12/4/2017 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>CzUP</td>\n",
       "      <td>75,00</td>\n",
       "      <td>torrijas parque a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>506.0</td>\n",
       "      <td>PALADARES CAFE</td>\n",
       "      <td>8/6/2008 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>AnUP</td>\n",
       "      <td>2,00</td>\n",
       "      <td>paladares cafe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id               description         order_date  section store  \\\n",
       "207       887.0  TARRINA MACEDONIA FRUTAS  4/11/2014 0:00:00        0  EnUP   \n",
       "26        209.0  EMP. HOJALDRE JAMON YORK  30/6/2008 0:00:00        0  BmUP   \n",
       "619       720.0          ECLAIR CHOCOLATE  5/12/2013 0:00:00        0  RzUP   \n",
       "685       160.0         TORRIJAS PEQUEรAS  12/4/2017 0:00:00        0  CzUP   \n",
       "107       506.0            PALADARES CAFE   8/6/2008 0:00:00        0  AnUP   \n",
       "\n",
       "    units_ordered           desc_normalized  \n",
       "207          0,00  tarrina macedonia frutas  \n",
       "26           0,00    el hojaldre jamon york  \n",
       "619          0,00          eclair chocolate  \n",
       "685         75,00         torrijas parque a  \n",
       "107          2,00            paladares cafe  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_merge = pd.DataFrame(dict(description = df_descriptions_unique, desc_normalized = df_descriptions_normalized))\n",
    "\n",
    "df_with_normalized_descriptions = pd.merge(df, to_merge, how='left', on = 'description').sort_values(by='order_date')\n",
    "df_with_normalized_descriptions.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - 'df' has the same size as 'df_with_normalized_descriptions' \n"
     ]
    }
   ],
   "source": [
    "#Control merge size:\n",
    "if (df.shape[0] == df_with_normalized_descriptions.shape[0] ): \n",
    "    test0 = \"OK - 'df' has the same size as 'df_with_normalized_descriptions' \"\n",
    "else:\n",
    "    test0 = \"ERROR - 'df' has NOT the same size as 'df_with_normalized_descriptions' \"\n",
    "print(test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product descritions were cleaned from 578 unique names to 569.\n"
     ]
    }
   ],
   "source": [
    "# Checking effectiveness of the data cleaning:\n",
    "unique_descriptions_raw = len(df['description'].unique())\n",
    "unique_descriptions_normalized = len(df_with_normalized_descriptions['desc_normalized'].unique())\n",
    "print('The product descritions were cleaned from {} unique names to {}.'.format(unique_descriptions_raw,unique_descriptions_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not super effective..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the file to the intermiady folder\n",
    "output_path_df_with_normalized_descriptions = exit_path + 'data_with_normalized_names.csv'\n",
    "df_with_normalized_descriptions.to_csv(output_path_df_with_normalized_descriptions, index = False, sep = ';' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Identifying product descriptions that the client wants us to predict\n",
    "\n",
    "It is time to create the file that will be manually reviewed.\n",
    "\n",
    "- First, we compare the normalized descriptions with the list of products provided with the client, and suggest matches using the library fuzzywuzzy\n",
    "- Second, we will use the results from the other analysis.\n",
    "- third, we will manually evaluate if the results are good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Using the library fuzzywuzzy to compare the product normalized descriptions with the list of products provided by the client and suggest a match, or alternatively - \"match-not-found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized_desc_unique = pd.DataFrame(df_with_normalized_descriptions[\"desc_normalized\"].unique(), columns = ['desc_normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match (line, options = list_of_products):\n",
    "    \"Returns product match if the the calculated difference between strings is greater than 80, 'match-not-found' otherwise\"\n",
    "    if not(line is None) and type(line)== str:\n",
    "        highest = process.extractOne(line,list_of_products)\n",
    "        if not(highest is None) and highest[1] >80:\n",
    "            return highest[0]\n",
    "        else:\n",
    "            return 'match-not-found'\n",
    "    else:\n",
    "        return 'match-not-found'\n",
    "\n",
    "# Applying matching function to all product normalized descriptions\n",
    "df_normalized_desc_unique[\"target_names_fuzzywuuzy\"] = df_normalized_desc_unique[\"desc_normalized\"].apply(lambda line: find_match(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now evaluate how effectively did we match the normalized descriptions with the list that the client provided us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_fuzzywuuzy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>postres mousse tres chocolates</td>\n",
       "      <td>match-not-found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>tarta mousse 3 chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>postres mousse chocolate en vasito</td>\n",
       "      <td>match-not-found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>mousse 3 chocolates 3</td>\n",
       "      <td>tarta mousse 3 chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>mousse de salmon</td>\n",
       "      <td>tarta mousse 3 chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>pasteles de mousse de pistacho</td>\n",
       "      <td>tarta de manzana 2ยบ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>mousse chocolate blanco</td>\n",
       "      <td>match-not-found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>mousse de hora opcion</td>\n",
       "      <td>match-not-found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tarta mousse tres chocolates del 2</td>\n",
       "      <td>tarta mousse 3 chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>postres mousse frutas bosque</td>\n",
       "      <td>match-not-found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        desc_normalized    target_names_fuzzywuuzy\n",
       "22       postres mousse tres chocolates            match-not-found\n",
       "50                mousse 3 chocolates 2  tarta mousse 3 chocolates\n",
       "60   postres mousse chocolate en vasito            match-not-found\n",
       "115               mousse 3 chocolates 3  tarta mousse 3 chocolates\n",
       "168                    mousse de salmon  tarta mousse 3 chocolates\n",
       "174      pasteles de mousse de pistacho        tarta de manzana 2ยบ\n",
       "218             mousse chocolate blanco            match-not-found\n",
       "270               mousse de hora opcion            match-not-found\n",
       "291  tarta mousse tres chocolates del 2  tarta mousse 3 chocolates\n",
       "326        postres mousse frutas bosque            match-not-found"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets review the effectiveness filtering by 'mousse '. The expected result is that all 'mousse 3 chocolates' match\n",
    "df_normalized_desc_unique[df_normalized_desc_unique['desc_normalized'].str.contains('mousse')].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see... its not actually very good, lets try something different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Using the results from the other analysis\n",
    "\n",
    "Lets now use the results from the manual analysis to see how efective the measure was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>nuevo_descrip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>446.0</td>\n",
       "      <td>postre tartaleta limon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>619.0</td>\n",
       "      <td>bocaditos de nata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>816.0</td>\n",
       "      <td>san marquitos (postre)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>486.0</td>\n",
       "      <td>tronco vainilla  y chocolate negro 70%  8  rac.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>609.0</td>\n",
       "      <td>no-description</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                    nuevo_descrip\n",
       "0       446.0                           postre tartaleta limon\n",
       "1       619.0                                bocaditos de nata\n",
       "2       816.0                           san marquitos (postre)\n",
       "3       486.0  tronco vainilla  y chocolate negro 70%  8  rac.\n",
       "4       609.0                                   no-description"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descriptions_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this matching is performed at id level, \n",
    "# lets create a new dataset with unique product_id, descriptions, and evaluate it:\n",
    "df_normalized_id_desc_unique = df_descriptions_unique[[\"product_id\",'nuevo_descrip']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_products_matches={100: 'croissant', \n",
    "                  101: 'croissant',\n",
    "                  102: 'croissant',\n",
    "                  103: 'croissant petit',\n",
    "                  9999: 'tarta mousse 3 chocolates', # almost only for order, creating a new id for this product is suggested\n",
    "                  462: 'tarta de manzana 2ยบ',\n",
    "                  182: 'palmera de chocolate', # palmeras: 140\n",
    "                  414: 'tarta opera', # 9999, for order, mostly. If included, creating a new id for this product is suggested\n",
    "                  4511:'postre fresas y mascarpone',\n",
    "                  459: 'milhojas frambuesa 2ยบ',\n",
    "                  112: 'tortel',\n",
    "                  115: 'baguette'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_names_a(product_id, dict_of_products_matches= dict_of_products_matches):\n",
    "    'Returns match if the product_id is found within the given dict or, otherise \"match-not-found\"'\n",
    "    if not(product_id is None) and not(math.isnan(product_id)) and int(product_id)  in dict_of_products_matches:\n",
    "        return dict_of_products_matches[int(product_id)]\n",
    "    else:\n",
    "        return 'match-not-found'\n",
    "    \n",
    "df_normalized_id_desc_unique['target_names_manual_analysis']=df_normalized_id_desc_unique[\"product_id\"].apply(lambda line: target_names_a(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now check how effective this was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>nuevo_descrip</th>\n",
       "      <th>target_names_manual_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>100.0</td>\n",
       "      <td>croisants</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>213.0</td>\n",
       "      <td>croisants sobrasada pq crudos</td>\n",
       "      <td>match-not-found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>106.0</td>\n",
       "      <td>croisants vacios</td>\n",
       "      <td>match-not-found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id                  nuevo_descrip target_names_manual_analysis\n",
       "64        100.0                      croisants                    croissant\n",
       "755       213.0  croisants sobrasada pq crudos              match-not-found\n",
       "784       106.0               croisants vacios              match-not-found"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets review the effectiveness filtering by 'mousse '. The expected result is that all 'mousse 3 chocolates' match\n",
    "df_normalized_id_desc_unique[df_normalized_id_desc_unique['nuevo_descrip'].str.contains('croisant')].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not very good, since most of the 'mousse 3 chocolates' are unmatched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that we need an better way to match the results. Lets try doing keywords filtering product by product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Review Product by Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, lets create again a dataframe with unique descriptions\n",
    "unique_normalized_decriptions = pd.DataFrame(df_normalized_id_desc_unique['nuevo_descrip'].unique(), columns = ['nuevo_descrip'])\n",
    "\n",
    "#And a empty list to add all the unitary analysis. It will be use to concatenate results.\n",
    "list_of_dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Matching: milhojas de frambuesa 2ยบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-59a1315d29ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmilhojas_frambuesa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target_names_prod_by_prod'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'milhojas frambuesa'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlist_of_dfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmilhojas_frambuesa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmilhojas_frambuesa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   4863\u001b[0m                              \"provide positive value.\")\n\u001b[0;32m   4864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4865\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4866\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "milhojas = unique_normalized_decriptions[unique_normalized_decriptions['nuevo_descrip'].str.contains('milhojas')]\n",
    "milhojas_frambuesa = milhojas[milhojas['nuevo_descrip'].str.contains('frambuesa')].copy()\n",
    "milhojas_frambuesa['target_names_prod_by_prod'] = 'milhojas frambuesa'\n",
    "list_of_dfs.append(milhojas_frambuesa)\n",
    "milhojas_frambuesa.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Matching: croissant petite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>croissant petit</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>petit a croissant pastas</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              desc_normalized target_names_prod_by_prod\n",
       "58            croissant petit                 croissant\n",
       "207  petit a croissant pastas                 croissant"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croissant = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('croissant')].copy()\n",
    "croissant_petite = croissant[croissant['desc_normalized'].str.contains('petit')].copy()\n",
    "croissant_petite['target_names_prod_by_prod'] = 'croissant'\n",
    "list_of_dfs.append(croissant_petite)\n",
    "croissant_petite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Matching: croissant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>croissant</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>croissant alargado grande piezas</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>croissant sobrasada px cocido</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>croissant integral</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>croissant racion</td>\n",
       "      <td>croissant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      desc_normalized target_names_prod_by_prod\n",
       "100                         croissant                 croissant\n",
       "166  croissant alargado grande piezas                 croissant\n",
       "213     croissant sobrasada px cocido                 croissant\n",
       "228                croissant integral                 croissant\n",
       "332                  croissant racion                 croissant"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croissant = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('croissant')].copy()\n",
    "croissant_simple = croissant[~croissant['desc_normalized'].str.contains('petit|tira|masa')].copy()\n",
    "croissant_simple['target_names_prod_by_prod'] = 'croissant'\n",
    "list_of_dfs.append(croissant_simple)\n",
    "croissant_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Matching: mousse tres chocolates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>postres mousse tres chocolates</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>postres mousse chocolate en vasito</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>mousse 3 chocolates 3</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tarta mousse tres chocolates del 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        desc_normalized target_names_prod_by_prod\n",
       "22       postres mousse tres chocolates    mousse tres chocolates\n",
       "50                mousse 3 chocolates 2    mousse tres chocolates\n",
       "60   postres mousse chocolate en vasito    mousse tres chocolates\n",
       "115               mousse 3 chocolates 3    mousse tres chocolates\n",
       "291  tarta mousse tres chocolates del 2    mousse tres chocolates"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mousse = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('mousse')].copy()\n",
    "mousse_tres = mousse[mousse['desc_normalized'].str.contains('tres|3')].copy()\n",
    "mousse_tres_chocolates = mousse_tres[mousse_tres['desc_normalized'].str.contains('chocolate')].copy()\n",
    "mousse_tres_chocolates['target_names_prod_by_prod'] = 'mousse tres chocolates'\n",
    "list_of_dfs.append(mousse_tres_chocolates)\n",
    "mousse_tres_chocolates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Matching: tarta de manzana 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>tarta caramelo y manzana 2</td>\n",
       "      <td>tarta de manzana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                desc_normalized target_names_prod_by_prod\n",
       "515  tarta caramelo y manzana 2          tarta de manzana"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manzana = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('manzana')]\n",
    "manzana_tarta = manzana[manzana['desc_normalized'].str.contains('tarta')].copy()\n",
    "manzana_tarta_dos = manzana_tarta[manzana_tarta['desc_normalized'].str.contains('dos|2')].copy()\n",
    "manzana_tarta_dos['target_names_prod_by_prod'] = 'tarta de manzana'\n",
    "list_of_dfs.append(manzana_tarta_dos)\n",
    "manzana_tarta_dos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.6 Matching: palmera de chocolate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>palmera de trufa</td>\n",
       "      <td>palmera chocolate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      desc_normalized target_names_prod_by_prod\n",
       "133  palmera de trufa         palmera chocolate"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palmera = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('palmera')]\n",
    "palmera_chocolate = palmera[palmera['desc_normalized'].str.contains('chocolate|trufa')].copy()\n",
    "palmera_chocolate['target_names_prod_by_prod'] = 'palmera chocolate'\n",
    "\n",
    "list_of_dfs.append(palmera_chocolate)\n",
    "palmera_chocolate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.7 Matching: tarta รณpera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tarta chocolate opera 1</td>\n",
       "      <td>tarta opera</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            desc_normalized target_names_prod_by_prod\n",
       "49  tarta chocolate opera 1               tarta opera"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('opera')]\n",
    "opera_tarta = opera[opera['desc_normalized'].str.contains('tarta')].copy()\n",
    "opera_tarta['target_names_prod_by_prod'] = 'tarta opera'\n",
    "\n",
    "list_of_dfs.append(opera_tarta)\n",
    "opera_tarta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.9 Matching: postre de fresas y mascarpone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>postres eclair fresas y mascarpone</td>\n",
       "      <td>postre de fresas y mascarpone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        desc_normalized      target_names_prod_by_prod\n",
       "410  postres eclair fresas y mascarpone  postre de fresas y mascarpone"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postre = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('postre')]\n",
    "postre_fresa = postre[postre['desc_normalized'].str.contains('fresa')].copy()\n",
    "postre_fresa_mascarpone = postre_fresa[postre_fresa['desc_normalized'].str.contains('mascarpone')].copy()\n",
    "\n",
    "postre_fresa_mascarpone['target_names_prod_by_prod'] = 'postre de fresas y mascarpone'\n",
    "list_of_dfs.append(postre_fresa_mascarpone)\n",
    "postre_fresa_mascarpone.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.9 Matching: tortel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mini torteles cruda</td>\n",
       "      <td>tortel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>torteles</td>\n",
       "      <td>tortel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>mini torteles piezas hora 5</td>\n",
       "      <td>tortel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 desc_normalized target_names_prod_by_prod\n",
       "39           mini torteles cruda                    tortel\n",
       "208                     torteles                    tortel\n",
       "495  mini torteles piezas hora 5                    tortel"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tortel = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('tortel')].copy()\n",
    "tortel['target_names_prod_by_prod'] = 'tortel'\n",
    "list_of_dfs.append(tortel)\n",
    "tortel.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.10 Matching: baguette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>baguette mallorca</td>\n",
       "      <td>baguette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>baguet piezas 5 hora</td>\n",
       "      <td>baguette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>baguett mallorca</td>\n",
       "      <td>baguette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>baguet</td>\n",
       "      <td>baguette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          desc_normalized target_names_prod_by_prod\n",
       "51      baguette mallorca                  baguette\n",
       "265  baguet piezas 5 hora                  baguette\n",
       "279      baguett mallorca                  baguette\n",
       "513                baguet                  baguette"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baguette = unique_normalized_decriptions[unique_normalized_decriptions['desc_normalized'].str.contains('baguette|baguete|baguet')].copy()\n",
    "baguette['target_names_prod_by_prod'] = 'baguette'\n",
    "list_of_dfs.append(baguette)\n",
    "baguette.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets now concatenate results, merge them back to the  full list of normalized descriptions and evaluate its effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets concatenate the results:\n",
    "list_of_products_df = pd.concat(list_of_dfs, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [desc_normalized, target_names_prod_by_prod]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_products_df[list_of_products_df['desc_normalized'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc_normalezed_vs_prod_by_prod = pd.merge(df_with_normalized_descriptions, list_of_products_df[['desc_normalized','target_names_prod_by_prod']],how='left',on = 'desc_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - 'df_with_normalized_descriptions' has the same size as 'df_with_normalized_descriptions' \n"
     ]
    }
   ],
   "source": [
    "#Control merge size:\n",
    "if (df_with_normalized_descriptions.shape[0] == df_desc_normalezed_vs_prod_by_prod.shape[0] ): \n",
    "    test1 = \"OK - 'df_with_normalized_descriptions' has the same size as 'df_with_normalized_descriptions' \"\n",
    "else:\n",
    "    test1 = \"ERROR - 'df' has NOT the same size as 'df_with_normalized_descriptions' \"\n",
    "\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "\n",
    "During the first executions of code with the full transactions file, this error was failing; 'df' had less rows than 'df_with_normalized_descriptions'. The reason for this was not easy to identify, however digging we found that that in the normalized description two products descriptions ware naming two different products in the description, however this was not the case for the raw description (before the spell-cheacker):\n",
    "\n",
    "for example:\n",
    "- Normalized prod description: 'tarta mousse 3 chocolates de 20 raciones con escrito sobre la tarta manzana y mini felicidades'\n",
    "- Raw description: 'TARTA MOUSSE 3 CHOCOLATES DE 20 RACIONES CON ESCRITO SOBRE LA TARTA:  MARIANA Y DANI FELICIDADES'\n",
    "\n",
    "Basically, the spell-corrector was solving some problems; normalizing 'trata' , 'taaarta' under 'tarta', but adding a new one: normalizing words that it doesnt know, that may be a correct word, to a word that it knows: 'MARIANA' to 'manzana'... Ofcourse this is a weakness, however from the manual inspections that were performed, it doesnt seem to happen often.\n",
    "\n",
    "How we solve it by adding to the bakery products dataset: \n",
    "- A list of the most common male and female spanish names: in order to avoid confusion in the names\n",
    "\n",
    "sources of the datasets:\n",
    "- spanish names:https://www.ine.es/dyngs/INEbase/es/operacion.htm?c=Estadistica_C&cid=1254736177009&menu=resultados&secc=1254736195454&idp=1254734710990\n",
    "\n",
    "\n",
    "Also, in this case we added some names that we found to the excel; the right thing to do should we had more time, would be to polish the dataset, by adding not just mallorca catalogue and names, but also a book in spanish. Perhaps, it would also be interesting to applying NLP to identify NAMES from the product descriptions and add them to the products dataset..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now check how effective it was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empanadas mariana de carne</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inglesitos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>empanadas hojaldre y bonito 6 a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paladares cafe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eclair blanco</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>barrita de frambuesa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>barqueta de tostas artesanas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tarta quiche espinacas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fondue chocolate blanco</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>moda pan espinacas g</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   desc_normalized target_names_prod_by_prod\n",
       "0       empanadas mariana de carne                       NaN\n",
       "1                       inglesitos                       NaN\n",
       "2  empanadas hojaldre y bonito 6 a                       NaN\n",
       "3                   paladares cafe                       NaN\n",
       "4                    eclair blanco                       NaN\n",
       "5             barrita de frambuesa                       NaN\n",
       "6     barqueta de tostas artesanas                       NaN\n",
       "7           tarta quiche espinacas                       NaN\n",
       "8          fondue chocolate blanco                       NaN\n",
       "9             moda pan espinacas g                       NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at the first 10 description names\n",
    "df_desc_normalezed_vs_prod_by_prod[['desc_normalized','target_names_prod_by_prod']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>postres mousse tres chocolates</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>postres mousse chocolate en vasito</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>mousse 3 chocolates 3</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>postres mousse tres chocolates</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>mousse de salmon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>pasteles de mousse de pistacho</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>postres mousse tres chocolates</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>mousse 3 chocolates 3</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>mousse chocolate blanco</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>mousse de salmon</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        desc_normalized target_names_prod_by_prod\n",
       "22       postres mousse tres chocolates    mousse tres chocolates\n",
       "56                mousse 3 chocolates 2    mousse tres chocolates\n",
       "69   postres mousse chocolate en vasito    mousse tres chocolates\n",
       "117               mousse 3 chocolates 2    mousse tres chocolates\n",
       "129               mousse 3 chocolates 3    mousse tres chocolates\n",
       "171      postres mousse tres chocolates    mousse tres chocolates\n",
       "198                    mousse de salmon                       NaN\n",
       "205      pasteles de mousse de pistacho                       NaN\n",
       "234               mousse 3 chocolates 2    mousse tres chocolates\n",
       "238      postres mousse tres chocolates    mousse tres chocolates\n",
       "242               mousse 3 chocolates 3    mousse tres chocolates\n",
       "261               mousse 3 chocolates 2    mousse tres chocolates\n",
       "281             mousse chocolate blanco                       NaN\n",
       "290               mousse 3 chocolates 2    mousse tres chocolates\n",
       "293                    mousse de salmon                       NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets now review the effectiveness filtering by 'mousse '. The expected result is that all 'mousse 3 chocolates' match\n",
    "df_desc_normalezed_vs_prod_by_prod.loc[df_desc_normalezed_vs_prod_by_prod['desc_normalized'].str.contains('mousse'),['desc_normalized','target_names_prod_by_prod'] ].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better! lets now check that the data integrity has not been compromised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Test that data has not been corrputed\n",
    "\n",
    "To test the integrity of the data, the original dataset should be the same as the last dataset without that we added, in other words, without the columns with the normalized descriptuons, and the target names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1000, 6)\n",
      "Resulting dataset shape: (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "# First, lets check the size of both dataframes:\n",
    "print(\"Original dataset shape: {}\".format(df.shape))\n",
    "print(\"Resulting dataset shape: {}\".format(df_desc_normalezed_vs_prod_by_prod.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape looks good, we were expecting the resulting dataset to have to columns more. Lets now evauate if they are actually the same dataset if we remove the added columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting original columnsd from the resulting df\n",
    "df_result = df_desc_normalezed_vs_prod_by_prod.loc[:, df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets compare it with the original dataset, sorting them out in the same way:\n",
    "df_result_sorted = df_result.sort_values(by = ['order_date','store','description','product_id', 'units_ordered']).reset_index().drop('index', axis = 1)\n",
    "df_original_sorted = df.sort_values(by = ['order_date','store','description',  'product_id', 'units_ordered']).reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>order_date</th>\n",
       "      <th>section</th>\n",
       "      <th>store</th>\n",
       "      <th>units_ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291.0</td>\n",
       "      <td>EMPANADA MEDIANA  DE CARNE</td>\n",
       "      <td>1/1/2008 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>GoUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.0</td>\n",
       "      <td>INGLESITOS</td>\n",
       "      <td>1/1/2016 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>JPUP</td>\n",
       "      <td>1,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202.0</td>\n",
       "      <td>Empanada Hojaldre y Bonito 6 rac.</td>\n",
       "      <td>1/10/2017 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>AaUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>506.0</td>\n",
       "      <td>PALADARES CAFE</td>\n",
       "      <td>1/11/2009 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>AaUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721.0</td>\n",
       "      <td>ECLAIR BLANCO</td>\n",
       "      <td>1/11/2017 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>BmUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                        description         order_date  section  \\\n",
       "0       291.0         EMPANADA MEDIANA  DE CARNE   1/1/2008 0:00:00        0   \n",
       "1       175.0                         INGLESITOS   1/1/2016 0:00:00        0   \n",
       "2       202.0  Empanada Hojaldre y Bonito 6 rac.  1/10/2017 0:00:00        0   \n",
       "3       506.0                     PALADARES CAFE  1/11/2009 0:00:00        0   \n",
       "4       721.0                      ECLAIR BLANCO  1/11/2017 0:00:00        0   \n",
       "\n",
       "  store units_ordered  \n",
       "0  GoUP          0,00  \n",
       "1  JPUP          1,00  \n",
       "2  AaUP          0,00  \n",
       "3  AaUP          0,00  \n",
       "4  BmUP          0,00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>order_date</th>\n",
       "      <th>section</th>\n",
       "      <th>store</th>\n",
       "      <th>units_ordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291.0</td>\n",
       "      <td>EMPANADA MEDIANA  DE CARNE</td>\n",
       "      <td>1/1/2008 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>GoUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175.0</td>\n",
       "      <td>INGLESITOS</td>\n",
       "      <td>1/1/2016 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>JPUP</td>\n",
       "      <td>1,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202.0</td>\n",
       "      <td>Empanada Hojaldre y Bonito 6 rac.</td>\n",
       "      <td>1/10/2017 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>AaUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>506.0</td>\n",
       "      <td>PALADARES CAFE</td>\n",
       "      <td>1/11/2009 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>AaUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>721.0</td>\n",
       "      <td>ECLAIR BLANCO</td>\n",
       "      <td>1/11/2017 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>BmUP</td>\n",
       "      <td>0,00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                        description         order_date  section  \\\n",
       "0       291.0         EMPANADA MEDIANA  DE CARNE   1/1/2008 0:00:00        0   \n",
       "1       175.0                         INGLESITOS   1/1/2016 0:00:00        0   \n",
       "2       202.0  Empanada Hojaldre y Bonito 6 rac.  1/10/2017 0:00:00        0   \n",
       "3       506.0                     PALADARES CAFE  1/11/2009 0:00:00        0   \n",
       "4       721.0                      ECLAIR BLANCO  1/11/2017 0:00:00        0   \n",
       "\n",
       "  store units_ordered  \n",
       "0  GoUP          0,00  \n",
       "1  JPUP          1,00  \n",
       "2  AaUP          0,00  \n",
       "3  AaUP          0,00  \n",
       "4  BmUP          0,00  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - The original dataset is the similar to the resulting dataset\n"
     ]
    }
   ],
   "source": [
    "# Now that they have the same columns, and are sorted using the same criteria, lets evaluate if they are the same:\n",
    "comparison_result = df_result_sorted.equals(df_original_sorted)\n",
    "\n",
    "if comparison_result == True:\n",
    "    test2 = 'OK - The original dataset is the similar to the resulting dataset'\n",
    "else:\n",
    "     test2 ='ERROR - The original dataset are NOT found'\n",
    "\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Filter dataset to only include the products from the list provided by the client, and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_products = df_desc_normalezed_vs_prod_by_prod[~df_desc_normalezed_vs_prod_by_prod['target_names_prod_by_prod'].isnull()]\n",
    "df_other_products = df_desc_normalezed_vs_prod_by_prod[df_desc_normalezed_vs_prod_by_prod['target_names_prod_by_prod'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>description</th>\n",
       "      <th>order_date</th>\n",
       "      <th>section</th>\n",
       "      <th>store</th>\n",
       "      <th>units_ordered</th>\n",
       "      <th>desc_normalized</th>\n",
       "      <th>target_names_prod_by_prod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>450.0</td>\n",
       "      <td>POSTRE MOUSSE TRES CHOCOLATES</td>\n",
       "      <td>10/10/2010 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>GrUP</td>\n",
       "      <td>0,00</td>\n",
       "      <td>postres mousse tres chocolates</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2999.0</td>\n",
       "      <td>MINI TORTELES CRUDOS</td>\n",
       "      <td>10/8/2008 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>MoUP</td>\n",
       "      <td>11,00</td>\n",
       "      <td>mini torteles cruda</td>\n",
       "      <td>tortel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4401.0</td>\n",
       "      <td>TARTA CHOCOLATE  PERA 1ยบ</td>\n",
       "      <td>11/2/2008 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>PoUP</td>\n",
       "      <td>0,00</td>\n",
       "      <td>tarta chocolate opera 1</td>\n",
       "      <td>tarta opera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>451.0</td>\n",
       "      <td>MOUSSE 3 CHOCOLATES 2ยบ</td>\n",
       "      <td>11/2/2014 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>GrUP</td>\n",
       "      <td>0,00</td>\n",
       "      <td>mousse 3 chocolates 2</td>\n",
       "      <td>mousse tres chocolates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>115.0</td>\n",
       "      <td>BAGUETTE MALLORCA</td>\n",
       "      <td>11/3/2017 0:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>AeUP</td>\n",
       "      <td>0,00</td>\n",
       "      <td>baguette mallorca</td>\n",
       "      <td>baguette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id                    description          order_date  section  \\\n",
       "22       450.0  POSTRE MOUSSE TRES CHOCOLATES  10/10/2010 0:00:00        0   \n",
       "40      2999.0           MINI TORTELES CRUDOS   10/8/2008 0:00:00        0   \n",
       "53      4401.0       TARTA CHOCOLATE  PERA 1ยบ   11/2/2008 0:00:00        0   \n",
       "56       451.0         MOUSSE 3 CHOCOLATES 2ยบ   11/2/2014 0:00:00        0   \n",
       "57       115.0              BAGUETTE MALLORCA   11/3/2017 0:00:00        0   \n",
       "\n",
       "   store units_ordered                 desc_normalized  \\\n",
       "22  GrUP          0,00  postres mousse tres chocolates   \n",
       "40  MoUP         11,00             mini torteles cruda   \n",
       "53  PoUP          0,00         tarta chocolate opera 1   \n",
       "56  GrUP          0,00           mousse 3 chocolates 2   \n",
       "57  AeUP          0,00               baguette mallorca   \n",
       "\n",
       "   target_names_prod_by_prod  \n",
       "22    mousse tres chocolates  \n",
       "40                    tortel  \n",
       "53               tarta opera  \n",
       "56    mousse tres chocolates  \n",
       "57                  baguette  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_products_file_name = exit_path + 'filtered_transactions_not_clean.csv' \n",
    "df_target_products.to_csv(df_target_products_file_name, index = False, sep = ';' )\n",
    "df_target_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f348a7bf49de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_unfiltered_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexit_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'unfiltered_transactions.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_unfiltered_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_unfiltered_products\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m';'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_unfiltered_products\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "df_unfiltered_products = exit_path + 'unfiltered_transactions.csv' \n",
    "df_unfiltered_products_name.to_csv(df_unfiltered_products_name, index = False, sep = ';' )\n",
    "df_unfiltered_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - 'df' has the same size as 'df_with_normalized_descriptions' \n",
      "OK - 'df_with_normalized_descriptions' has the same size as 'df_with_normalized_descriptions' \n",
      "OK - The original dataset is the similar to the resulting dataset\n"
     ]
    }
   ],
   "source": [
    "print(test0)\n",
    "print(test1)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
